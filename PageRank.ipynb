{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"random_walk\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper1(x):\n",
    "    return_list = []\n",
    "    for element in x[1][0][1]:\n",
    "        return_list.append((int(element), 0.8 * ( x[1][1] / x[1][0][0])))\n",
    "    return return_list\n",
    "def mapper3(x):\n",
    "    if x[1][1] == None:\n",
    "        return (x[0], x[1][0])\n",
    "    return (x[0], x[1][0] + x[1][1])\n",
    "    \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056\t0.000632\n",
      "1054\t0.000629\n",
      "1536\t0.000524\n",
      "171\t0.000512\n",
      "453\t0.000496\n",
      "407\t0.000485\n",
      "263\t0.000480\n",
      "4664\t0.000470\n",
      "261\t0.000463\n",
      "410\t0.000462\n"
     ]
    }
   ],
   "source": [
    "data = sc.textFile(\"p2p-Gnutella04.txt\")\n",
    "nodes = 10876\n",
    "\n",
    "extractor1 = data.filter(lambda x: x[0] != '#').map(lambda x : (int(x.split('\\t')[0]), int(x.split('\\t')[1])))\n",
    "extractor2 = data.filter(lambda x: x[0] != '#').map(lambda x : (int(x.split('\\t')[0]), 1))\n",
    "\n",
    "r_new = extractor1.flatMap(lambda x: [(x[0],0.2 * 1/nodes), (x[1],0.2 * 1/nodes)]).reduceByKey(lambda x,y: x)\n",
    "ans = extractor1.flatMap(lambda x: [(x[0],0.2 * 1/nodes), (x[1],1/nodes)]).reduceByKey(lambda x,y: x)\n",
    "\n",
    "table = extractor1.groupByKey().mapValues(tuple)\n",
    "Count = extractor2\n",
    "degree = Count.reduceByKey(lambda x,y: x+y)\n",
    "M = degree.join(table)\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    R_old = ans\n",
    "    R_new = r_new\n",
    "    tmp = M.join(R_old) #(j, (out_deg, (i....), r_old))\n",
    "    to_sum_M = tmp.flatMap(mapper1).reduceByKey(lambda x,y: x+y)\n",
    "    af_mul = R_new.leftOuterJoin(to_sum_M).map(mapper3)\n",
    "    y = af_mul.map(lambda x : x[1]).sum()\n",
    "    ans = af_mul.map(lambda x: (x[0], x[1] + (1-y)/nodes ))\n",
    "    \n",
    "Sorted = ans.sortBy(lambda x: x[1], False).collect() \n",
    "\n",
    "for i in range(10):\n",
    "    print('%d\\t%f'%(Sorted[i][0],round(Sorted[i][1], 6)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RageRank\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## preprocess:\n",
    "\n",
    "\n",
    "```python=\n",
    "def mapper1(x):\n",
    "    return_list = []\n",
    "    for element in x[1][0][1]:\n",
    "        return_list.append((int(element), 0.8 * ( x[1][1] / x[1][0][0])))\n",
    "    return return_list\n",
    "\n",
    "def mapper3(x):\n",
    "    if x[1][1] == None:\n",
    "        return (x[0], x[1][0])\n",
    "    return (x[0], x[1][0] + x[1][1])\n",
    "```\n",
    "\n",
    "\n",
    "首先會先做出兩組pair的RDD，\n",
    "\n",
    "```python=\n",
    "extractor1 = data.filter(lambda x: x[0] != '#').map(lambda x : (int(x.split('\\t')[0]), int(x.split('\\t')[1])))\n",
    "extractor2 = data.filter(lambda x: x[0] != '#').map(lambda x : (int(x.split('\\t')[0]), 1))\n",
    "\n",
    "r_new = extractor1.flatMap(lambda x: [(x[0],0.2 * 1/nodes), (x[1],0.2 * 1/nodes)]).reduceByKey(lambda x,y: x)\n",
    "r_old = extractor1.flatMap(lambda x: [(x[0],0.2 * 1/nodes), (x[1],1/nodes)]).reduceByKey(lambda x,\n",
    "\n",
    "```\n",
    "\n",
    "分別為r_new以及r_old:\n",
    "\n",
    "\n",
    "$$ r_{new} =  (i ,\\dfrac{1-\\displaystyle \\beta}{N}) $$\n",
    "$$ r_{old} =  (i ,\\dfrac{1}{N}) $$\n",
    "\n",
    "N, beta分別為node的數量與定義好的常數\n",
    "\n",
    "做法是把input file做一次flatmap給予pair正確的數值，把edge起點和終點的node以(node_id, initial_value)的方式都丟進RDD，這麼一來就會把每個node都創造出來且不會遺漏，然後再做一次reduce把key一樣的放在起並只return其中一個，這樣就可以避免node重複出現。\n",
    "\n",
    "接者做出matrix:\n",
    "\n",
    "```python=\n",
    "table = extractor1.groupByKey().mapValues(tuple)\n",
    "Count = extractor2\n",
    "degree = Count.reduceByKey(lambda x,y: x+y)\n",
    "M = degree.join(table)\n",
    "tmp = M.join(R_old)\n",
    "```\n",
    "\n",
    "\n",
    "$$tmp =  (j, (outdeg_j, (node1_{j->i}, node2_{j->i}, node3_{j->i}, node4_{j->i}, ...), R_{old, j}) $$\n",
    "\n",
    "\n",
    "先將j所有的pair從extractor group在一起，形成(j, node1,node2...)。\n",
    "接者，將原始data map成(j, 1)放進Count裡面，然後做reduce，把1全部加起來，找出node j的out degree(j, outdeg)。最後把兩個RDD join在一起，把剛剛做出來的RDD(j, (outdeg ,(node1, node2, node3...)))和R_old join起來。\n",
    "\n",
    "## iteration part:\n",
    "\n",
    "```python=\n",
    "for i in range(20):\n",
    "    R_old = ans\n",
    "    R_new = r_new\n",
    "    tmp = M.join(R_old) #(j, (out_deg, (i....), r_old))\n",
    "    to_sum_M = tmp.flatMap(mapper1).reduceByKey(lambda x,y: x+y)\n",
    "    af_mul = R_new.leftOuterJoin(to_sum_M).map(mapper3)\n",
    "    y = af_mul.map(lambda x : x[1]).sum()\n",
    "    ans = af_mul.map(lambda x: (x[0], x[1] + (1-y)/nodes ))\n",
    "```\n",
    "\n",
    "將r_new初始化為：\n",
    "\n",
    "$$ r_{new} =  (i ,\\dfrac{1-\\displaystyle \\beta}{N}) $$\n",
    "\n",
    "r_old初始為上一次iteration的r_new\n",
    "\n",
    "產生一個RDD:\n",
    "\n",
    "$$ (i, r_{tmp}) $$\n",
    "\n",
    "\n",
    "做法是把剛剛做完的matrix RDD (tmp) 用mapper1 map成：\n",
    "$$(nodek_{j->i}, 0.8*\\frac{r_{old,j}}{outdeg_j})$$\n",
    "\n",
    "接者把這些pair和r_new join起來，並且用mapper3把pair裡面的value相加。下一步，會算出r_new的和，並且對r_new做一次map，normalize成：\n",
    "\n",
    "$$ (node, r_{new} + \\frac {1-summation_{r_{new}}}{N})$$\n",
    "\n",
    "完成一次iteration\n",
    "\n",
    "\n",
    "\n",
    "結果：\n",
    "```\n",
    "1056\t0.000632\n",
    "1054\t0.000629\n",
    "1536\t0.000524\n",
    "171\t0.000512\n",
    "453\t0.000496\n",
    "407\t0.000485\n",
    "263\t0.000480\n",
    "4664\t0.000470\n",
    "261\t0.000463\n",
    "410\t0.000462\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}